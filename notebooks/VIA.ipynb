{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "cell_style": "center"
   },
   "source": [
    "<img src=\"../images/demos/FIUM.png\" width=\"350px\" class=\"pull-right\" style=\"display: inline-block\">\n",
    "\n",
    "# Visión Artificial\n",
    "\n",
    "### 4º de Grado en Ingeniería Informática\n",
    "\n",
    "Curso 2018-2019<br>\n",
    "Prof. *[Alberto Ruiz](http://dis.um.es/profesores/alberto)*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- [libro de Szeliski](http://szeliski.org/Book/drafts/SzeliskiBook_20100903_draft.pdf)\n",
    "\n",
    "- [OpenCV](https://opencv.org/), [tutoriales en Python](https://docs.opencv.org/3.3.1/d6/d00/tutorial_py_root.html)\n",
    "\n",
    "- [scikit-image](http://scikit-image.org/), [scikit-learn](http://scikit-learn.org)\n",
    "\n",
    "\n",
    "- [datasets](https://en.wikipedia.org/wiki/List_of_datasets_for_machine_learning_research#Image_data)\n",
    "\n",
    "\n",
    "- [Python](https://docs.python.org/3.6/)\n",
    "\n",
    "- [numpy](http://www.numpy.org/), [scipy](http://docs.scipy.org/doc/scipy/reference/)\n",
    "\n",
    "- [matplotlib](http://matplotlib.org/index.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 0. Presentación (4/2/19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "[introducción](intro.ipynb), [instalación](install.ipynb), [Python](python.ipynb)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Introducción a la asignatura\n",
    "\n",
    "- Repaso de Python, numpy y matplotib"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Introducción a la imagen digital (11/2/19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[imagen](imagen.ipynb), [gráficas](graphs.ipynb), [canales de color](color.ipynb), [indexado/stacks](stacks.ipynb), [dispositivos de captura](captura.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Imagen digital: rows, cols, depth, step. Planar or pixel order. Tipo de pixel: byte vs float\n",
    "\n",
    "- Color encoding: RGB vs YUV vs HSV\n",
    "\n",
    "- Campo de visión (FOV, *field of view*, parámetro $f$)\n",
    "\n",
    "- Coordendas de pixel, coordenadas normalizadas (indep de resolución), coordenadas calibradas (independiente del FOV).\n",
    "\n",
    "- Aspect ratio. Resize.\n",
    "\n",
    "- ROI, masks\n",
    "\n",
    "- Manipulación: slice regions, \"stack\" de imágenes\n",
    "\n",
    "- primitivas gráficas\n",
    "\n",
    "- captura: webcams, cameras ip, archivos de vídeo, v4l2-ctl, etc. Load / save.\n",
    "\n",
    "- entornos de conda, pyqtgraph, pycharm, spyder\n",
    "\n",
    "- Herramientas: formatos de imagen, imagemagick, gimp, mplayer/mencoder/ffmpeg, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Manipulación de imágenes (18/2/19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[histograma](histogram.ipynb), [efecto chroma](chroma.ipynb), [segmentación por color](colorseg.ipynb)\n",
    "<br>\n",
    "[cuantización de color](codebook.ipynb), [transformaciones de dominio](lookup.ipynb) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Histograma, transformaciones de valor (brillo, contraste), ecualización\n",
    "\n",
    "- Transformaciones de dominio (deformaciones), lookup table.\n",
    "\n",
    "- chroma key\n",
    "\n",
    "- reproyección de histograma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Filtros digitales (25/2/19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[filtros de imagen](filtros.ipynb), [análisis frecuencial](fourier.ipynb), [filtrado inverso](inversefilt.ipynb), [transformada de distancia](transf-dist.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- lineal\n",
    "\n",
    "    - convolution\n",
    "    - máscaras para paso alto, bajo, etc.\n",
    "    - separabilidad\n",
    "    - integral image, box filter\n",
    "    - dominio frecuencial\n",
    "    - [inverse filtering](http://yuzhikov.com/articles/BlurredImagesRestoration1.htm), [Wiener](https://www.cis.rit.edu/class/simg782/lectures/lecture_16/lec782_05_16.pdf)\n",
    "\n",
    "\n",
    "- no lineal\n",
    "\n",
    "    - mediana\n",
    "    - min, max\n",
    "    - algoritmos generales\n",
    "\n",
    "\n",
    "- Gaussian filter\n",
    "\n",
    "    - separabilidad\n",
    "    - cascading\n",
    "    - Fourier\n",
    "\n",
    "\n",
    "\n",
    "- [morphological operations](http://docs.opencv.org/master/d9/d61/tutorial_py_morphological_ops.html#gsc.tab=0)\n",
    "\n",
    "    - structuring element\n",
    "    - dilate, erode\n",
    "    - open, close\n",
    "    - gradient\n",
    "    - fill holes\n",
    "\n",
    "\n",
    "- Transformada de distancia"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  4. Detección de bordes (4/3/19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[detección de bordes](bordes.ipynb), [Canny nms en C](cannyC.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gradiente: visualización como *vector field*\n",
    "\n",
    "- operador de Canny\n",
    "\n",
    "- transformada de Hough\n",
    "\n",
    "- Histograma de orientaciones del gradiente (HOG)\n",
    "\n",
    "- implementación simple de HOG\n",
    "\n",
    "- detección de *pedestrians*\n",
    "\n",
    "- face landmarks (dlib)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Flujo Óptico (11/3/19)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[elipse de incertidumbre](covarianza.ipynb), [optical flow](harris.ipynb)\n",
    "\n",
    "- elipse de incertidumbre\n",
    "\n",
    "- cross-correlation\n",
    "\n",
    "- corners (Harris)\n",
    "\n",
    "- Lucas-Kanade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. *keypoints*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[keypoints](keypoints.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- modelo cuadrático\n",
    "\n",
    "- blobs / saddle points (Hessian)\n",
    "\n",
    "- SIFT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. reconocimiento de formas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[shapes](shapes.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- umbralización\n",
    "\n",
    "- manipulación de contornos\n",
    "\n",
    "- invariantes frecuenciales de forma"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### X. otras técnicas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[varios](varios.ipynb), [textura](textura.ipynb), [`grabcut.py`](../code/grabcut.py)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Detección de caras mediante *adaboost* ([Viola & Jones, 2001](https://en.wikipedia.org/wiki/Viola%E2%80%93Jones_object_detection_framework))\n",
    "\n",
    "- Segmentación de objetos mediante *GrabCut* ([Rother et al. 2004](https://cvg.ethz.ch/teaching/cvl/2012/grabcut-siggraph04.pdf), [tutorial](http://docs.opencv.org/3.2.0/d8/d83/tutorial_py_grabcut.html))\n",
    "\n",
    "- Clasificación de texturas mediante *LBP* ([Wang and He, 1990](http://www.academia.edu/download/46467306/0031-3203_2890_2990135-820160614-8960-12m30mo.pdf), [wiki](https://en.wikipedia.org/wiki/Local_binary_patterns))\n",
    "\n",
    "- Herramientas para OCR (*[tesseract](https://github.com/tesseract-ocr)*)\n",
    "\n",
    "- Herramientas para códigos de barras y QR (*[zbar](http://zbar.sourceforge.net/)*)\n",
    "\n",
    "- Detección de elipses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. coordenadas homogéneas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Comenzamos el estudio de la geometría visual."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[perspectiva](geovis.ipynb), [coordenadas homogéneas](coordhomog.ipynb), [sistemas de ecuaciones](sistecs.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transformaciones lineales\n",
    "\n",
    "- espacios lineales, vectores\n",
    "\n",
    "- transformaciones lineales, matrices\n",
    "\n",
    "- producto escalar (**dot** product)\n",
    "\n",
    "- producto vectorial (**cross** product)\n",
    "\n",
    "- puntos, rectas, planos, meet & join"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Geometría del plano\n",
    "\n",
    "- coordenadas homogéneas\n",
    "\n",
    "- interpretación como rayos\n",
    "\n",
    "- puntos y rectas del plano\n",
    "\n",
    "- incidencia e intersección, dualidad\n",
    "\n",
    "- puntos del infinito, recta del infinito\n",
    "\n",
    "- manejo natural de puntos del infinito\n",
    "\n",
    "- horizonte de un plano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. transformaciones del plano"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[transformaciones del plano](transf2D.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Desplazamientos, rotaciones, escalado uniforme, escalado general, proyectividad.\n",
    "\n",
    "- Grupos euclídeo, similar, afín, proyectivo.\n",
    "\n",
    "- Propiedades invariantes de cada grupo.\n",
    "\n",
    "- Representación como matriz homogénea $3\\times 3$ y tipos de matriz de cada grupo.\n",
    "\n",
    "- *Cross ratio* de 4 puntos en una recta. De 5 rectas.\n",
    "\n",
    "- Estimación de transformaciones a partir de correspondencias.\n",
    "\n",
    "- Aplicaciones: rectificación de planos, mosaico de imágenes.\n",
    "\n",
    "Avanzado\n",
    "\n",
    "- Transformación de rectas. Covarianza y contravarianza.\n",
    "\n",
    "- Cónicas: incidencia, tangencia, (pole-polar), cónica dual, transformación.\n",
    "\n",
    "- Objetos invariantes en cada grupo de transformaciones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 11. modelo de cámara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[modelo de la cámara](camera.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Espacio proyectivo: puntos y líneas 3D, planos, grados de libertad, plano del infinito, analogía con 2D.\n",
    "\n",
    "- Grupos de transformaciones 3D: y sus invariantes.\n",
    "\n",
    "- Modelo pinhole (proyección), cámara oscura, lente.\n",
    "\n",
    "- Transformación de perspectiva: proyección $\\mathcal P^3 \\rightarrow\\mathcal P ^2$.\n",
    "\n",
    "- cámara calibrada C=PRT, 6 dof, parámetros extrínsecos o pose.\n",
    "\n",
    "- calibración, distorsión radial.\n",
    "\n",
    "- Matriz de cámara estándar $M=K[R|t]$.\n",
    "\n",
    "- Matriz de calibración $K$ y campo visual. Calibración \"a ojo\" de una cámara mediante estimación de su FOV.\n",
    "\n",
    "- PnP (*pose from n points*).\n",
    "\n",
    "- Realidad aumentada.\n",
    "\n",
    "- Anatomía de la cámara\n",
    "\n",
    "- Rotaciones sintéticas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimentos\n",
    "\n",
    "- calibración precisa usando \"chessboard\" y `calibrate.py`\n",
    "\n",
    "- Rectificación de planos mediante rotaciones sintéticas. Intenta medir la distancia entre monedas en la imagen `coins.png` buscando una rotación sintética que rectifique el rectángulo de la escena.\n",
    "\n",
    "- Experimenta con [ARToolkit](http://artoolkit.org).\n",
    "\n",
    "- Echa un vistazo a [PTAM](http://www.robots.ox.ac.uk/~gk/PTAM)\n",
    "\n",
    "- Navegación visual de robots.\n",
    "\n",
    "- Haz un programa que capture con la webcam la imagen de un sudoku y lo resuelva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 12. visión estéreo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[stereo](stereo.ipynb), [stereo-challenge](stereo-challenge.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Triangulación\n",
    "\n",
    "- Geometría epipolar\n",
    "\n",
    "- Extracción de cámaras\n",
    "\n",
    "- Rectificación estéreo\n",
    "\n",
    "- Mapas de profundidad\n",
    "\n",
    "\n",
    "Experimentos\n",
    "\n",
    "- Reproduce los experimentos con un par estéreo tomado con tu propia cámara usando el *tracker* de puntos estudiado en una clase anterior.\n",
    "\n",
    "- Intenta poner en marcha el sistema [VisualSFM](http://ccwu.me/vsfm/)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 13. *deep learning*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[machine learning](machine-learning.ipynb), [tensorflow](tensorflow.ipynb), [imagenet](imagenet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Repaso de *Machine Learning* y *Pattern Recognition*\n",
    "\n",
    "- Repaso de computación neuronal\n",
    "\n",
    "- Introducción a la redes convolucionales\n",
    "\n",
    "- *Deep Learning* en visión artificial."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [introducción](intro.ipynb)\n",
    "1. [instalación](install.ipynb)\n",
    "1. [Python](python.ipynb)\n",
    "\n",
    "1. [dispositivos de captura](captura.ipynb)\n",
    "\n",
    "1. [imagen](imagen.ipynb)\n",
    "1. [gráficas](graphs.ipynb)\n",
    "1. [canales de color](color.ipynb)\n",
    "\n",
    "1. [indexado, stacks](stacks.ipynb)\n",
    "1. [histograma](histogram.ipynb)\n",
    "1. [efecto chroma](chroma.ipynb)\n",
    "1. [segmentación por color](colorseg.ipynb)\n",
    "1. [cuantización de color](codebook.ipynb)\n",
    "\n",
    "1. [transformaciones de dominio](lookup.ipynb) \n",
    "\n",
    "1. [filtros de imagen](filtros.ipynb)\n",
    "1. [análisis frecuencial](fourier.ipynb)\n",
    "1. [filtrado inverso](inversefilt.ipynb)\n",
    "\n",
    "1. [transformada de distancia](transf-dist.ipynb)\n",
    "\n",
    "1. [detección de bordes](bordes.ipynb)\n",
    "\n",
    "1. [técnicas auxiliares](ipmisc.ipynb)\n",
    "1. [Canny nms en C](cannyC.ipynb)\n",
    "\n",
    "1. [keypoints](keypoints.ipynb)\n",
    "\n",
    "1. [elipse de incertidumbre](covarianza.ipynb)\n",
    "1. [optical flow](harris.ipynb)\n",
    "\n",
    "1. [sistemas de ecuaciones](sistecs.ipynb)\n",
    "\n",
    "1. [textura](textura.ipynb)\n",
    "\n",
    "1. [shapes](shapes.ipynb)\n",
    "\n",
    "1. [varios](varios.ipynb)\n",
    "\n",
    "1. [perspectiva](geovis.ipynb)\n",
    "1. [coordenadas homogéneas](coordhomog.ipynb)\n",
    "1. [transformaciones del plano](transf2D.ipynb)\n",
    "1. [DLT](DLT.ipynb)\n",
    "\n",
    "1. [modelo de cámara](camera.ipynb)\n",
    "\n",
    "1. [visión stereo](stereo.ipynb)\n",
    "1. [stereo-challenge](stereo-challenge.ipynb)\n",
    "\n",
    "1. [machine learning](machine-learning.ipynb)\n",
    "1. [tensorflow](tensorflow.ipynb)\n",
    "1. [imagenet database](imagenet.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejemplos de código"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. [`hello.py`](../code/hello.py): lee imagen de archivo, la reescala, muestra y sobreescribe un texto.\n",
    "\n",
    "1. [`webcam.py`](../code/webcam.py): muestra la secuencia de imágenes capturadas por una webcam.\n",
    "\n",
    "1. [`2cams.py`](../code/2cams.py): combina las imágenes tomadas por dos cámaras.\n",
    "\n",
    "1. [`player.py`](../code/player.py): función auxiliar que permite aplicar una cierta función a la secuencia de imágenes, con opción de guardar (S) y parar el vídeo (espacio).\n",
    "\n",
    "1. [`mouse.py`](../code/mouse.py): ejemplo de captura de eventos de ratón.\n",
    "\n",
    "1. [`trackbar.py`](../code/trackbar.py): ejemplo de parámetro interactivo.\n",
    "\n",
    "1. [`stream.py`](../code/stream.py): ejemplo de uso de la fuente genérica de imágenes \"mkStream\".\n",
    "\n",
    "1. [`stream2.py`](../code/stream2.py): ejemplo de mkStream para leer un conjunto de imágenes en disco mostrándolas y avanzando de una en una pulsando una tecla.\n",
    "\n",
    "1. [`deque.py`](../code/deque.py): procesamiento de las $n$ imágenes más recientes.\n",
    "\n",
    "1. [`mjpegserver.py`](../code/mjpegserver.py): servidor de secuencias de video en formato mjpeg.\n",
    "\n",
    "1. [`histogram.py`](../code/histogram.py): histograma en vivo con opencv.\n",
    "\n",
    "1. [`histogram2.py`](../code/histogram2.py): histograma en vivo con matplotlib.\n",
    "\n",
    "1. [`surface.py`](../code/surface.py): superficie 3D de niveles de gris en vivo usando pyqtgraph.\n",
    "\n",
    "1. [`backsub.py`](../code/backsub.py): eliminación de fondo mediante MOG2.\n",
    "\n",
    "1. [`server.py`](../code/server.py): ejemplo de servidor web de imágenes capturadas con la webcam.\n",
    "\n",
    "1. [`bot`](../code/bot): bots de [Telegram](https://python-telegram-bot.org/).\n",
    "\n",
    "1. [`reprohist.py`](../code/reprohist.py): reproyección de histograma.\n",
    "\n",
    "1. [`camshift.py`](../code/camshift.py): tracking mediante reproyección de histograma.\n",
    "\n",
    "1. [`grabcut.py`](../code/grabcut.py): segmentación de objetos interactiva mediante GrabCut.\n",
    "\n",
    "1. [`spectral.py`](../code/spectral.py): FFT en vivo.\n",
    "\n",
    "1. [`thread`](../code/thread): captura y procesamiento concurrente.\n",
    "\n",
    "1. [`testC.py`](../code/testC.py), [`inC`](../code/inC): Interfaz C-numpy.\n",
    "\n",
    "1. [`hog/pedestrian.py`](../code/hog/pedestrian.py): detector de peatones de opencv.\n",
    "\n",
    "1. [`hog/facelandmarks.py`](../code/hog/facelandmarks.py): detector de caras y landmarks de dlib.\n",
    "\n",
    "1. [`hog/hog0.py`](../code/hog/hog0.py): experimentos con hog.\n",
    "\n",
    "1. [`regressor.py`](../code/regressor.py): predictor directo de la posición de una región.\n",
    "\n",
    "1. [`sift.py`](../code/sift.py): demostración de la detección de keypoints y búsqueda de coincidencias en imágenes en vivo.\n",
    "\n",
    "1. [`lk_base.py`](../code/lk_base.py), [`lk_track.py`](../code/lk_track.py): seguimiento de puntos con el método de Lucas-Kanade.\n",
    "\n",
    "1. [`pose.py`](../code/pose.py), [`pose3D.py`](../code/pose3D.py): estimación de pose y realidad aumentada."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicios propuestos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los marcados con asterisco son obligatorios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** 1**. Estima de forma aproximada el campo de visión ([FOV](https://en.wikipedia.org/wiki/Angle_of_view)) y parámetro $f$ de tu cámara. Determina a qué altura habría que ponerla para obtener una vista cenital completa de un campo de baloncesto. Calcula la altura de una pelota sobre el suelo a partir de su tamaño en la imagen. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2**. Modifica los canales de color (brillo, saturación, etc.) de una secuencia de imágenes en vivo con un \"trackbar\"."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**3**. Amplia `player.py` o `stream.py` para seleccionar con el ratón una región de interés (ROI) y almacenar los recortes en una lista, y opcionalmente en disco. Este programa nos servirá como base para futuros ejercicios."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** 4**. Construye un detector de movimiento basado en una sencilla diferencia de imágenes sucesivas. Opcionalmente puedes hacer un generador que filtre la secuencia de imágenes dejando pasar solo los frames estáticos (o, alternativamente, los que han sufrido un cambio apreciable. En este caso no hace falta detectar las zonas con movimiento). Puedes apoyarte en `deque.py`. Opcional: a) Limitar la detección a una región de interés. b) Guardar 2 ó 3 segundos de la secuencia detectada en un archivo de vídeo o imagen gif."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**5**. Implementa el efecto chroma con imágenes en vivo de la webcam. Pulsando una tecla se captura el fondo y los objetos que aparezcan se superponen en otra imagen o secuencia de video. Compara el resultado con el método automático de eliminación de fondo ilustrado en `backsub.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** 6**. Construye un clasificador de objetos en base a la similitud de los histogramas de color del ROI (de los 3 canales por separado). Apóyate en 3."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**7**. Implementa la segmentación por color usando reproyección de histogramas en un programa que admite como argumento a) una carpeta con trozos de imágen que sirven como muestras de color y b) otra imagen o secuencia de video que deseamos clasificar. El resultado puede ser un conjunto de máscaras para cada clase, o una \"imagen de etiquetas\", donde diferentes colores indican cada una de las regiones."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** 8**. Muestra el efecto de diferentes filtros sobre la imagen en vivo de la webcam. Selecciona con el teclado el filtro deseado y modifica sus posibles parámetros (p.ej. el nivel de suavizado) con las teclas de flecha. Es conveniente permitir la selección de un ROI para comparar el resultado del filtro con el resto de la imagen."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**9**. Construye un servidor web sencillo usando [flask](http://flask.pocoo.org/) que muestre una cierta transformación, especificada en la url, de las imágenes tomadas con la cámara. Apóyate en `server.py`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**10**. Escribe una aplicación de tu invención que utilice los [marcadores de cara](https://ibug.doc.ic.ac.uk/resources/facial-point-annotations/) obtenidos por el *shape detector* disponible en [dlib](http://dlib.net/) (ejemplo `/hog/facelandmarks.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**. Escribe una aplicación de reconocimiento de objetos con la webcam basada en el número de coincidencias de *keypoints*. Pulsando una tecla se pueden ir guardando modelos (p. ej. carátulas de CD, portadas de libros, cuadros de pintores, etc.). Cuando detectamos que la imagen está bastante quieta, o cuando se pulse otra tecla, calculamos los puntos de interés de la imagen actual y sus descriptores y comprobamos si hay suficientes coincidencias con los de algún modelo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**. Calcula una estimación del movimiento de la cámara analizando las trayectorias obtenidas por el *tracker* de Lucas-Kanade (ejemplo `lk_track.py`)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**. Escribe una aplicación de reconocimiento de siluetas con la webcam basado en descriptores frecuenciales."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**. Rectifica la imagen de un plano para medir distancias (tomando manualmente referencias conocidas). Por ejemplo, mide la distancia entre las monedas en `coins.png` o la distancia a la que se realiza el disparo en `gol-eder.png`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**. Crea automáticamente un mosaico panorámico ajustando varias imágenes (>2). Recuerda que debe tratarse de una escena plana o de una escena cualquiera vista desde el mismo centro de proyección."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**. Realiza una calibración precisa de tu cámara mediante múltiples imágenes de un *chessboard*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**. Crea un efecto de realidad aumentada dinámico."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**E**. Resuelve los problemas planteados en el notebook [stereo-challenge](stereo-challenge.ipynb)."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
